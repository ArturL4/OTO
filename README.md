# OTO (Online Training Optimazation)

### Table of Contents
1. [Installation](#installation)
2. [Project Motivation](#motivation)
3. [File Description](#files)
4. [Results](#results)
5. [Licensing, Authors, and Acknowlegements](#licensing)

## Installation <a name= "installation"></a>
To use OTO the standard libraries given with the Anaconda Distribution.<br>
Furthermore you need to install the PyTorch Framework as described [here](https://pytorch.org/get-started/locally/).


## Project Motivation <a name="motivation"></a>

Training a Neural Network with static Hyperparameter Configurations can be very time consuming and might don't even result in good accuracies.<br>
The idea behind OTO is to actually give the Network itself the oppurtinity to decide whether to change the Hyperparameters.<br>
We believe that giving the Network a variety of Hyperparameters while training it is possible to reduce the error and enhance the training time.

## File Description <a name="files"></a>


## Results <a name="results"></a>


## Licensing, Authors, Ackowlegements <a name="licensing"></a>
